{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import arff, numpy as np\n",
    "# dataset = arff.load(open('mydataset.arff', 'rb'))\n",
    "# data = np.array(dataset['data'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T11:42:37.530192882Z",
     "start_time": "2023-10-08T11:42:37.499673915Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T11:42:38.827013589Z",
     "start_time": "2023-10-08T11:42:38.688950576Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_example_df = arff.loadarff('OpenML/data/1.arff')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T11:42:46.820787033Z",
     "start_time": "2023-10-08T11:42:46.749082137Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_example_df = pd.DataFrame(data_example_df[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T11:42:58.126344204Z",
     "start_time": "2023-10-08T11:42:57.924027165Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    family product-type steel  carbon  hardness temper_rolling condition  \\\n0     b'?'         b'C'  b'A'     8.0       0.0           b'?'      b'S'   \n1     b'?'         b'C'  b'R'     0.0       0.0           b'?'      b'S'   \n2     b'?'         b'C'  b'R'     0.0       0.0           b'?'      b'S'   \n3     b'?'         b'C'  b'A'     0.0      60.0           b'T'      b'?'   \n4     b'?'         b'C'  b'A'     0.0      60.0           b'T'      b'?'   \n..     ...          ...   ...     ...       ...            ...       ...   \n893   b'?'         b'C'  b'R'     0.0       0.0           b'?'      b'S'   \n894   b'?'         b'C'  b'R'     0.0       0.0           b'?'      b'S'   \n895   b'?'         b'C'  b'V'     0.0       0.0           b'?'      b'S'   \n896   b'?'         b'C'  b'A'     0.0      85.0           b'T'      b'?'   \n897   b'?'         b'C'  b'A'     0.0      85.0           b'T'      b'?'   \n\n    formability  strength non-ageing  ...   's'   'p'     shape  thick  \\\n0          b'?'       0.0       b'?'  ...  b'?'  b'?'   b'COIL'  0.700   \n1          b'2'       0.0       b'?'  ...  b'?'  b'?'   b'COIL'  3.200   \n2          b'2'       0.0       b'?'  ...  b'?'  b'?'  b'SHEET'  0.700   \n3          b'?'       0.0       b'?'  ...  b'?'  b'?'   b'COIL'  2.801   \n4          b'?'       0.0       b'?'  ...  b'?'  b'?'  b'SHEET'  0.801   \n..          ...       ...        ...  ...   ...   ...       ...    ...   \n893        b'3'       0.0       b'?'  ...  b'?'  b'?'  b'SHEET'  1.599   \n894        b'3'       0.0       b'?'  ...  b'?'  b'?'  b'SHEET'  1.601   \n895        b'2'       0.0       b'?'  ...  b'?'  b'?'  b'SHEET'  1.599   \n896        b'?'       0.0       b'?'  ...  b'?'  b'?'   b'COIL'  0.400   \n897        b'?'       0.0       b'?'  ...  b'?'  b'?'   b'COIL'  4.000   \n\n      width    len   oil    bore packing class  \n0     610.0    0.0  b'?'    b'0'    b'?'  b'3'  \n1     610.0    0.0  b'?'    b'0'    b'?'  b'3'  \n2    1300.0  762.0  b'?'    b'0'    b'?'  b'3'  \n3     385.1    0.0  b'?'    b'0'    b'?'  b'3'  \n4     255.0  269.0  b'?'    b'0'    b'?'  b'3'  \n..      ...    ...   ...     ...     ...   ...  \n893   610.0  762.0  b'?'    b'0'    b'?'  b'2'  \n894   830.0  880.0  b'?'    b'0'    b'?'  b'2'  \n895   150.0  762.0  b'?'    b'0'    b'?'  b'2'  \n896    20.0    0.0  b'?'    b'0'    b'?'  b'U'  \n897   610.0    0.0  b'?'  b'500'    b'?'  b'U'  \n\n[898 rows x 39 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>family</th>\n      <th>product-type</th>\n      <th>steel</th>\n      <th>carbon</th>\n      <th>hardness</th>\n      <th>temper_rolling</th>\n      <th>condition</th>\n      <th>formability</th>\n      <th>strength</th>\n      <th>non-ageing</th>\n      <th>...</th>\n      <th>'s'</th>\n      <th>'p'</th>\n      <th>shape</th>\n      <th>thick</th>\n      <th>width</th>\n      <th>len</th>\n      <th>oil</th>\n      <th>bore</th>\n      <th>packing</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'A'</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'?'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'COIL'</td>\n      <td>0.700</td>\n      <td>610.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'3'</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'R'</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'2'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'COIL'</td>\n      <td>3.200</td>\n      <td>610.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'3'</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'R'</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'2'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'SHEET'</td>\n      <td>0.700</td>\n      <td>1300.0</td>\n      <td>762.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'3'</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'A'</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>b'T'</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'COIL'</td>\n      <td>2.801</td>\n      <td>385.1</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'3'</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'A'</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>b'T'</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'SHEET'</td>\n      <td>0.801</td>\n      <td>255.0</td>\n      <td>269.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'3'</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>893</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'R'</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'3'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'SHEET'</td>\n      <td>1.599</td>\n      <td>610.0</td>\n      <td>762.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'2'</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'R'</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'3'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'SHEET'</td>\n      <td>1.601</td>\n      <td>830.0</td>\n      <td>880.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'2'</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'V'</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'2'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'SHEET'</td>\n      <td>1.599</td>\n      <td>150.0</td>\n      <td>762.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'2'</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'A'</td>\n      <td>0.0</td>\n      <td>85.0</td>\n      <td>b'T'</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'COIL'</td>\n      <td>0.400</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'U'</td>\n    </tr>\n    <tr>\n      <th>897</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'A'</td>\n      <td>0.0</td>\n      <td>85.0</td>\n      <td>b'T'</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'COIL'</td>\n      <td>4.000</td>\n      <td>610.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'500'</td>\n      <td>b'?'</td>\n      <td>b'U'</td>\n    </tr>\n  </tbody>\n</table>\n<p>898 rows × 39 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_example_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T11:43:11.470900730Z",
     "start_time": "2023-10-08T11:43:11.283802986Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data_meta_inf_df = pd.read_csv(\"OpenML/data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T11:43:21.876072916Z",
     "start_time": "2023-10-08T11:43:21.810566342Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "        id                 name   length       target\n0       10                lymph    22513        class\n1     1000          hypothyroid   276707  binaryClass\n2     1001               sponge    41487  binaryClass\n3     1002         ipumslasmall  2622855  binaryClass\n4     1003         primarytumor    22769  binaryClass\n...    ...                  ...      ...          ...\n1193   995         mfeatzernike   934793  binaryClass\n1194   996           prnnfglass    10062  binaryClass\n1195   997         balancescale     6440  binaryClass\n1196   998  analcatdatabondrate     4213  binaryClass\n1197   999            audiology    41616  binaryClass\n\n[1198 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>length</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>lymph</td>\n      <td>22513</td>\n      <td>class</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>hypothyroid</td>\n      <td>276707</td>\n      <td>binaryClass</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1001</td>\n      <td>sponge</td>\n      <td>41487</td>\n      <td>binaryClass</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1002</td>\n      <td>ipumslasmall</td>\n      <td>2622855</td>\n      <td>binaryClass</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1003</td>\n      <td>primarytumor</td>\n      <td>22769</td>\n      <td>binaryClass</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1193</th>\n      <td>995</td>\n      <td>mfeatzernike</td>\n      <td>934793</td>\n      <td>binaryClass</td>\n    </tr>\n    <tr>\n      <th>1194</th>\n      <td>996</td>\n      <td>prnnfglass</td>\n      <td>10062</td>\n      <td>binaryClass</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>997</td>\n      <td>balancescale</td>\n      <td>6440</td>\n      <td>binaryClass</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>998</td>\n      <td>analcatdatabondrate</td>\n      <td>4213</td>\n      <td>binaryClass</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>999</td>\n      <td>audiology</td>\n      <td>41616</td>\n      <td>binaryClass</td>\n    </tr>\n  </tbody>\n</table>\n<p>1198 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_meta_inf_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T11:43:24.210469795Z",
     "start_time": "2023-10-08T11:43:24.059943583Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "         id                               name  length     target\n351       2                             anneal   84089      class\n442       3                             krvskp  489987      class\n483       4                              labor    8244      class\n1097      9                              autos   30728  symboling\n0        10                              lymph   22513      class\n...     ...                                ...     ...        ...\n575   41004  junglechesspcsendgamelionelephant  744770      class\n576   41005        junglechesspcsendgameratrat  580258      class\n577   41006       junglechesspcsendgameratlion  924887      class\n578   41007      junglechesspcsendgamelionlion  372703      class\n579   41027   junglechesspcsrawendgamecomplete  627769      class\n\n[1198 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>length</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>351</th>\n      <td>2</td>\n      <td>anneal</td>\n      <td>84089</td>\n      <td>class</td>\n    </tr>\n    <tr>\n      <th>442</th>\n      <td>3</td>\n      <td>krvskp</td>\n      <td>489987</td>\n      <td>class</td>\n    </tr>\n    <tr>\n      <th>483</th>\n      <td>4</td>\n      <td>labor</td>\n      <td>8244</td>\n      <td>class</td>\n    </tr>\n    <tr>\n      <th>1097</th>\n      <td>9</td>\n      <td>autos</td>\n      <td>30728</td>\n      <td>symboling</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>lymph</td>\n      <td>22513</td>\n      <td>class</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>575</th>\n      <td>41004</td>\n      <td>junglechesspcsendgamelionelephant</td>\n      <td>744770</td>\n      <td>class</td>\n    </tr>\n    <tr>\n      <th>576</th>\n      <td>41005</td>\n      <td>junglechesspcsendgameratrat</td>\n      <td>580258</td>\n      <td>class</td>\n    </tr>\n    <tr>\n      <th>577</th>\n      <td>41006</td>\n      <td>junglechesspcsendgameratlion</td>\n      <td>924887</td>\n      <td>class</td>\n    </tr>\n    <tr>\n      <th>578</th>\n      <td>41007</td>\n      <td>junglechesspcsendgamelionlion</td>\n      <td>372703</td>\n      <td>class</td>\n    </tr>\n    <tr>\n      <th>579</th>\n      <td>41027</td>\n      <td>junglechesspcsrawendgamecomplete</td>\n      <td>627769</td>\n      <td>class</td>\n    </tr>\n  </tbody>\n</table>\n<p>1198 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_meta_inf_df.sort_values(by='id')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T11:43:28.026423179Z",
     "start_time": "2023-10-08T11:43:27.843074870Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Meta features extraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class MetaFeaturesExtractor:\n",
    "    def __init__(self, structured_data: pd.DataFrame):\n",
    "        self._meta_features_table = {\n",
    "                                    \"base_meta_features\": {\n",
    "                                        \"number_of_objects\": {\n",
    "                                            \"method\": self.get_number_of_objects\n",
    "                                            },\n",
    "                                        \"number_of_features\": {\n",
    "                                            \"method\": self.get_number_of_features\n",
    "                                            },\n",
    "                                        \"number_of_categorical_features\": {\n",
    "                                            \"method\": self.get_number_of_categorical_features\n",
    "                                            },\n",
    "                                        \"number_of_classes\": {\n",
    "                                            \"method\": self.get_number_of_classes\n",
    "                                            }\n",
    "                                        },\n",
    "                                    \"statistical_meta_features\": {\n",
    "                                        \"minimum\": {\n",
    "                                            \"method\": self.get_minimum\n",
    "                                            },\n",
    "                                        \"maximum\": {\n",
    "                                            \"method\": self.get_maximum\n",
    "                                            },\n",
    "                                        \"mean\": {\n",
    "                                            \"method\": self.get_mean\n",
    "                                            },\n",
    "                                        \"std\": {\n",
    "                                            \"method\": self.get_std\n",
    "                                            },\n",
    "                                         \"asymmetry_coef\":{\n",
    "                                             \"method\": self.get_asymmetry_coef\n",
    "                                            },\n",
    "                                         \"excess_coef\":{\n",
    "                                             \"method\": self.get_excess_coef\n",
    "                                            }\n",
    "                                          # Число значений категории.\n",
    "                                          # Энтропия вероятностей.\n",
    "                                          # Любая другая функция, которая агрегирует множество чисел в одно, если применить её к распределению вероятностей.\n",
    "                                        },\n",
    "                                    \"structural_meta_features\": {\n",
    "                                        \"vortex_depth\": {\n",
    "                                            \"method\": self.get_vortexes_depth\n",
    "                                            },\n",
    "                                        \"regression_coefs\": {\n",
    "                                            \"method\": self.get_regression_coefs\n",
    "                                            }\n",
    "                                        }\n",
    "                                    }\n",
    "        self._structured_data = structured_data\n",
    "        self._meta_object = {}\n",
    "        self._some_unstructured_meta_info_about_data = {}\n",
    "        self._preprocess_structured_data()\n",
    "\n",
    "\n",
    "    def _get_structured_data(self):\n",
    "        return self._structured_data\n",
    "\n",
    "\n",
    "    def _update_meta_object(self, meta_feature_name: str, meta_feature_value):\n",
    "        self._meta_object[meta_feature_name] = meta_feature_value\n",
    "\n",
    "\n",
    "    def _get_meta_features_table(self):\n",
    "        return self._meta_features_table\n",
    "\n",
    "\n",
    "    def _update_meta_feature_value(self, meta_feature_type, meta_feature_name, meta_feature_value):\n",
    "        self._meta_features_table[meta_feature_type][meta_feature_name][\"value\"] = meta_feature_value\n",
    "\n",
    "\n",
    "    def _get_unstructured_meta_info_about_data(self):\n",
    "        return self._some_unstructured_meta_info_about_data\n",
    "\n",
    "\n",
    "    def get_meta_object(self):\n",
    "        return self._meta_object\n",
    "\n",
    "    #===================================================================================\n",
    "\n",
    "    def _preprocess_structured_data(self):\n",
    "        data = self._get_structured_data()\n",
    "        self._some_unstructured_meta_info_about_data[\"data_pd_shape\"] = data.shape\n",
    "        self._some_unstructured_meta_info_about_data[\"data_pd_describe_numerical\"] = data.describe()\n",
    "        self._some_unstructured_meta_info_about_data[\"data_pd_describe_categorical\"] = data.describe(include=[\"object\", \"bool\"])\n",
    "        # ETC\n",
    "\n",
    "\n",
    "    def get_number_of_objects(self) -> float:\n",
    "        shape = self._get_unstructured_meta_info_about_data()[\"data_pd_shape\"]\n",
    "        return shape[0]\n",
    "\n",
    "\n",
    "    def get_number_of_features(self):\n",
    "        shape = self._get_unstructured_meta_info_about_data()[\"data_pd_shape\"]\n",
    "        return shape[1]\n",
    "\n",
    "\n",
    "    def get_number_of_categorical_features(self):\n",
    "        return self._get_unstructured_meta_info_about_data()[\"data_pd_describe_categorical\"].shape[1]\n",
    "\n",
    "\n",
    "    def get_number_of_classes(self):\n",
    "        return self._get_unstructured_meta_info_about_data()[\"data_pd_describe_categorical\"].iloc[:, -1][\"unique\"]\n",
    "\n",
    "\n",
    "    def get_minimum(self):\n",
    "        return self._get_unstructured_meta_info_about_data()[\"data_pd_describe_numerical\"].loc[\"min\"].min()\n",
    "\n",
    "\n",
    "    def get_maximum(self):\n",
    "        return self._get_unstructured_meta_info_about_data()[\"data_pd_describe_numerical\"].loc[\"max\"].max()\n",
    "\n",
    "\n",
    "    def get_mean(self):\n",
    "        return self._get_unstructured_meta_info_about_data()[\"data_pd_describe_numerical\"].loc[\"mean\"].mean()\n",
    "\n",
    "\n",
    "    def get_std(self):\n",
    "        return 8\n",
    "\n",
    "\n",
    "    def get_asymmetry_coef(self):\n",
    "        return 9\n",
    "\n",
    "\n",
    "    def get_excess_coef(self):\n",
    "        return 10\n",
    "\n",
    "\n",
    "    def get_vortexes_depth(self):\n",
    "        return 11\n",
    "\n",
    "\n",
    "    def get_regression_coefs(self):\n",
    "        return 12\n",
    "\n",
    "\n",
    "    #===================================================================================\n",
    "\n",
    "\n",
    "    def extract_meta_features(self):\n",
    "        meta_features_table = self._get_meta_features_table()\n",
    "        for _, meta_feature_type in enumerate(meta_features_table):\n",
    "            meta_feature_type_table = meta_features_table[meta_feature_type]\n",
    "            for _, meta_feature_name in enumerate(meta_feature_type_table):\n",
    "                meta_feature_table = meta_feature_type_table[meta_feature_name]\n",
    "                # print([meta_feature_type, meta_feature_name, meta_feature_table[\"method\"]])\n",
    "                meta_feature_value = meta_feature_table[\"method\"]()\n",
    "                self._update_meta_feature_value(meta_feature_type, meta_feature_name, meta_feature_value)\n",
    "                self._update_meta_object(meta_feature_name, meta_feature_value)\n",
    "        return\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "extractor = MetaFeaturesExtractor(data_example_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "extractor.extract_meta_features()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number_of_objects': 898, 'number_of_features': 39, 'number_of_categorical_features': 33, 'number_of_classes': 5, 'minimum': 0.0, 'maximum': 4880.0, 'mean': 348.50426818856744, 'std': 8, 'asymmetry_coef': 9, 'excess_coef': 10, 'vortex_depth': 11, 'regression_coefs': 12}\n"
     ]
    }
   ],
   "source": [
    "print(extractor.get_meta_object())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# knn\n",
    "# desision tree\n",
    "# linear regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# n_train = 150\n",
    "# n_test = 1000\n",
    "# noise = 0.1\n",
    "#\n",
    "#\n",
    "# def f(x):\n",
    "#     x = x.ravel()\n",
    "#     return np.exp(-(x ** 2)) + 1.5 * np.exp(-((x - 2) ** 2))\n",
    "#\n",
    "#\n",
    "# def generate(n_samples, noise):\n",
    "#     X = np.random.rand(n_samples) * 10 - 5\n",
    "#     X = np.sort(X).ravel()\n",
    "#     y = (\n",
    "#         np.exp(-(X ** 2))\n",
    "#         + 1.5 * np.exp(-((X - 2) ** 2))\n",
    "#         + np.random.normal(0.0, noise, n_samples)\n",
    "#     )\n",
    "#     X = X.reshape((n_samples, 1))\n",
    "#     return X, y\n",
    "#\n",
    "#\n",
    "# X_train, y_train = generate(n_samples=n_train, noise=noise)\n",
    "# X_test, y_test = generate(n_samples=n_test, noise=noise)\n",
    "#\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "#\n",
    "# reg_tree = DecisionTreeRegressor(max_depth=5, random_state=17)\n",
    "#\n",
    "# reg_tree.fit(X_train, y_train)\n",
    "# reg_tree_pred = reg_tree.predict(X_test)\n",
    "#\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(X_test, f(X_test), \"b\")\n",
    "# # plt.scatter(X_train, y_train, c=\"b\", s=20)\n",
    "# plt.plot(X_test, reg_tree_pred, \"g\", lw=2)\n",
    "# plt.xlim([-5, 5])\n",
    "# plt.title(\n",
    "#     \"Decision tree regressor, MSE = %.2f\"\n",
    "#     % (np.sum((y_test - reg_tree_pred) ** 2) / n_test)\n",
    "# )\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def split_data_train_test(dataframe: pd.DataFrame, frac: float = 0.2) -> List[pd.DataFrame]:\n",
    "    test = dataframe.sample(frac=frac, axis=0)\n",
    "    train = dataframe.drop(index=test.index)\n",
    "    return [train, test]\n",
    "\n",
    "\n",
    "def split_data_X_Y(dataframe: pd.DataFrame) -> List[np.ndarray]:\n",
    "    X = dataframe.iloc[:, 0:-1]\n",
    "    Y = dataframe.iloc[:, -1]\n",
    "    return [X, Y]\n",
    "\n",
    "\n",
    "def form_data(dataframe: pd.DataFrame) -> List[np.ndarray]:\n",
    "    [train, test] = split_data_train_test(dataframe)\n",
    "    [X_train, Y_train] = split_data_X_Y(train)\n",
    "    [X_test, Y_test] = split_data_X_Y(test)\n",
    "    return [X_train, Y_train, X_test, Y_test]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "    family product-type steel  carbon  hardness temper_rolling condition  \\\n0     b'?'         b'C'  b'A'     8.0       0.0           b'?'      b'S'   \n1     b'?'         b'C'  b'R'     0.0       0.0           b'?'      b'S'   \n2     b'?'         b'C'  b'R'     0.0       0.0           b'?'      b'S'   \n3     b'?'         b'C'  b'A'     0.0      60.0           b'T'      b'?'   \n4     b'?'         b'C'  b'A'     0.0      60.0           b'T'      b'?'   \n..     ...          ...   ...     ...       ...            ...       ...   \n893   b'?'         b'C'  b'R'     0.0       0.0           b'?'      b'S'   \n894   b'?'         b'C'  b'R'     0.0       0.0           b'?'      b'S'   \n895   b'?'         b'C'  b'V'     0.0       0.0           b'?'      b'S'   \n896   b'?'         b'C'  b'A'     0.0      85.0           b'T'      b'?'   \n897   b'?'         b'C'  b'A'     0.0      85.0           b'T'      b'?'   \n\n    formability  strength non-ageing  ...   's'   'p'     shape  thick  \\\n0          b'?'       0.0       b'?'  ...  b'?'  b'?'   b'COIL'  0.700   \n1          b'2'       0.0       b'?'  ...  b'?'  b'?'   b'COIL'  3.200   \n2          b'2'       0.0       b'?'  ...  b'?'  b'?'  b'SHEET'  0.700   \n3          b'?'       0.0       b'?'  ...  b'?'  b'?'   b'COIL'  2.801   \n4          b'?'       0.0       b'?'  ...  b'?'  b'?'  b'SHEET'  0.801   \n..          ...       ...        ...  ...   ...   ...       ...    ...   \n893        b'3'       0.0       b'?'  ...  b'?'  b'?'  b'SHEET'  1.599   \n894        b'3'       0.0       b'?'  ...  b'?'  b'?'  b'SHEET'  1.601   \n895        b'2'       0.0       b'?'  ...  b'?'  b'?'  b'SHEET'  1.599   \n896        b'?'       0.0       b'?'  ...  b'?'  b'?'   b'COIL'  0.400   \n897        b'?'       0.0       b'?'  ...  b'?'  b'?'   b'COIL'  4.000   \n\n      width    len   oil    bore packing class  \n0     610.0    0.0  b'?'    b'0'    b'?'  b'3'  \n1     610.0    0.0  b'?'    b'0'    b'?'  b'3'  \n2    1300.0  762.0  b'?'    b'0'    b'?'  b'3'  \n3     385.1    0.0  b'?'    b'0'    b'?'  b'3'  \n4     255.0  269.0  b'?'    b'0'    b'?'  b'3'  \n..      ...    ...   ...     ...     ...   ...  \n893   610.0  762.0  b'?'    b'0'    b'?'  b'2'  \n894   830.0  880.0  b'?'    b'0'    b'?'  b'2'  \n895   150.0  762.0  b'?'    b'0'    b'?'  b'2'  \n896    20.0    0.0  b'?'    b'0'    b'?'  b'U'  \n897   610.0    0.0  b'?'  b'500'    b'?'  b'U'  \n\n[898 rows x 39 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>family</th>\n      <th>product-type</th>\n      <th>steel</th>\n      <th>carbon</th>\n      <th>hardness</th>\n      <th>temper_rolling</th>\n      <th>condition</th>\n      <th>formability</th>\n      <th>strength</th>\n      <th>non-ageing</th>\n      <th>...</th>\n      <th>'s'</th>\n      <th>'p'</th>\n      <th>shape</th>\n      <th>thick</th>\n      <th>width</th>\n      <th>len</th>\n      <th>oil</th>\n      <th>bore</th>\n      <th>packing</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'A'</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'?'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'COIL'</td>\n      <td>0.700</td>\n      <td>610.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'3'</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'R'</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'2'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'COIL'</td>\n      <td>3.200</td>\n      <td>610.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'3'</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'R'</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'2'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'SHEET'</td>\n      <td>0.700</td>\n      <td>1300.0</td>\n      <td>762.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'3'</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'A'</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>b'T'</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'COIL'</td>\n      <td>2.801</td>\n      <td>385.1</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'3'</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'A'</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>b'T'</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'SHEET'</td>\n      <td>0.801</td>\n      <td>255.0</td>\n      <td>269.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'3'</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>893</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'R'</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'3'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'SHEET'</td>\n      <td>1.599</td>\n      <td>610.0</td>\n      <td>762.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'2'</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'R'</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'3'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'SHEET'</td>\n      <td>1.601</td>\n      <td>830.0</td>\n      <td>880.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'2'</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'V'</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'S'</td>\n      <td>b'2'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'SHEET'</td>\n      <td>1.599</td>\n      <td>150.0</td>\n      <td>762.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'2'</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'A'</td>\n      <td>0.0</td>\n      <td>85.0</td>\n      <td>b'T'</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'COIL'</td>\n      <td>0.400</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'0'</td>\n      <td>b'?'</td>\n      <td>b'U'</td>\n    </tr>\n    <tr>\n      <th>897</th>\n      <td>b'?'</td>\n      <td>b'C'</td>\n      <td>b'A'</td>\n      <td>0.0</td>\n      <td>85.0</td>\n      <td>b'T'</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>...</td>\n      <td>b'?'</td>\n      <td>b'?'</td>\n      <td>b'COIL'</td>\n      <td>4.000</td>\n      <td>610.0</td>\n      <td>0.0</td>\n      <td>b'?'</td>\n      <td>b'500'</td>\n      <td>b'?'</td>\n      <td>b'U'</td>\n    </tr>\n  </tbody>\n</table>\n<p>898 rows × 39 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_example_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "data_example_df = data_example_df.dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "X = data_example_df.iloc[:, 0:-1]\n",
    "Y = data_example_df.iloc[:, -1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "non_numeric_columns = list(X.describe(exclude=[np.number]).columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   onehotencoder__x0_b'?'  onehotencoder__x0_b'TN'  onehotencoder__x0_b'ZS'  \\\n",
      "0                     1.0                      0.0                      0.0   \n",
      "1                     1.0                      0.0                      0.0   \n",
      "2                     1.0                      0.0                      0.0   \n",
      "3                     1.0                      0.0                      0.0   \n",
      "4                     1.0                      0.0                      0.0   \n",
      "\n",
      "   onehotencoder__x1_b'C'  onehotencoder__x2_b'?'  onehotencoder__x2_b'A'  \\\n",
      "0                     1.0                     0.0                     1.0   \n",
      "1                     1.0                     0.0                     0.0   \n",
      "2                     1.0                     0.0                     0.0   \n",
      "3                     1.0                     0.0                     1.0   \n",
      "4                     1.0                     0.0                     1.0   \n",
      "\n",
      "   onehotencoder__x2_b'K'  onehotencoder__x2_b'M'  onehotencoder__x2_b'R'  \\\n",
      "0                     0.0                     0.0                     0.0   \n",
      "1                     0.0                     0.0                     1.0   \n",
      "2                     0.0                     0.0                     1.0   \n",
      "3                     0.0                     0.0                     0.0   \n",
      "4                     0.0                     0.0                     0.0   \n",
      "\n",
      "   onehotencoder__x2_b'S'  ...  onehotencoder__x30_b'600'  \\\n",
      "0                     0.0  ...                        0.0   \n",
      "1                     0.0  ...                        0.0   \n",
      "2                     0.0  ...                        0.0   \n",
      "3                     0.0  ...                        0.0   \n",
      "4                     0.0  ...                        0.0   \n",
      "\n",
      "   onehotencoder__x31_b'2'  onehotencoder__x31_b'3'  onehotencoder__x31_b'?'  \\\n",
      "0                      0.0                      0.0                      1.0   \n",
      "1                      0.0                      0.0                      1.0   \n",
      "2                      0.0                      0.0                      1.0   \n",
      "3                      0.0                      0.0                      1.0   \n",
      "4                      0.0                      0.0                      1.0   \n",
      "\n",
      "   carbon  hardness  strength  thick   width    len  \n",
      "0     8.0       0.0       0.0  0.700   610.0    0.0  \n",
      "1     0.0       0.0       0.0  3.200   610.0    0.0  \n",
      "2     0.0       0.0       0.0  0.700  1300.0  762.0  \n",
      "3     0.0      60.0       0.0  2.801   385.1    0.0  \n",
      "4     0.0      60.0       0.0  0.801   255.0  269.0  \n",
      "\n",
      "[5 rows x 84 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduard/anaconda3/envs/academic_experiments_conda_venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "transformer = make_column_transformer(\n",
    "    (OneHotEncoder(), non_numeric_columns),\n",
    "    remainder='passthrough')\n",
    "\n",
    "transformed = transformer.fit_transform(X)\n",
    "transformed_X = pd.DataFrame(transformed, columns=transformer.get_feature_names())\n",
    "print(transformed_X.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "['class']"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Y.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transуformed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [38]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m transformer \u001B[38;5;241m=\u001B[39m make_column_transformer(\n\u001B[1;32m      2\u001B[0m     (OneHotEncoder(), \u001B[38;5;28mlist\u001B[39m(pd\u001B[38;5;241m.\u001B[39mDataFrame(Y)\u001B[38;5;241m.\u001B[39mcolumns)),\n\u001B[1;32m      3\u001B[0m     remainder\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      5\u001B[0m transformed \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfit_transform(Y)\n\u001B[0;32m----> 6\u001B[0m transformed_Y \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\u001B[43mtransуformed\u001B[49m, columns\u001B[38;5;241m=\u001B[39mtransformer\u001B[38;5;241m.\u001B[39mget_feature_names_out())\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(transformed_Y\u001B[38;5;241m.\u001B[39mhead())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'transуformed' is not defined"
     ]
    }
   ],
   "source": [
    "transformer = make_column_transformer(\n",
    "    (OneHotEncoder(), list(pd.DataFrame(Y).columns)),\n",
    "    remainder='passthrough')\n",
    "\n",
    "transformed = transformer.fit_transform(Y)\n",
    "transformed_Y = pd.DataFrame(transуformed, columns=transformer.get_feature_names_out())\n",
    "print(transformed_Y.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([\"onehotencoder__class_b'1'\", \"onehotencoder__class_b'2'\",\n       \"onehotencoder__class_b'3'\", \"onehotencoder__class_b'5'\",\n       \"onehotencoder__class_b'U'\"], dtype=object)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# D_Tree on sample data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "[X_train, Y_train, X_test, Y_test] = form_data(data_example_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "non_numeric_columns = list(data_example_df.describe(exclude=[np.number]).columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# One-hot encoding multiple columns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from seaborn import load_dataset\n",
    "import pandas as pd\n",
    "#\n",
    "# df = load_dataset('penguins')\n",
    "# # df = df[['island', 'sex', 'body_mass_g']]\n",
    "data_example_df = data_example_df.dropna()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "count      898\nunique       5\ntop       b'3'\nfreq       684\nName: class, dtype: object"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_example_df[\"class\"]."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   onehotencoder__x0_b'?'  onehotencoder__x0_b'TN'  onehotencoder__x0_b'ZS'  \\\n",
      "0                     1.0                      0.0                      0.0   \n",
      "1                     1.0                      0.0                      0.0   \n",
      "2                     1.0                      0.0                      0.0   \n",
      "3                     1.0                      0.0                      0.0   \n",
      "4                     1.0                      0.0                      0.0   \n",
      "\n",
      "   onehotencoder__x1_b'C'  onehotencoder__x2_b'?'  onehotencoder__x2_b'A'  \\\n",
      "0                     1.0                     0.0                     1.0   \n",
      "1                     1.0                     0.0                     0.0   \n",
      "2                     1.0                     0.0                     0.0   \n",
      "3                     1.0                     0.0                     1.0   \n",
      "4                     1.0                     0.0                     1.0   \n",
      "\n",
      "   onehotencoder__x2_b'K'  onehotencoder__x2_b'M'  onehotencoder__x2_b'R'  \\\n",
      "0                     0.0                     0.0                     0.0   \n",
      "1                     0.0                     0.0                     1.0   \n",
      "2                     0.0                     0.0                     1.0   \n",
      "3                     0.0                     0.0                     0.0   \n",
      "4                     0.0                     0.0                     0.0   \n",
      "\n",
      "   onehotencoder__x2_b'S'  ...  onehotencoder__x32_b'2'  \\\n",
      "0                     0.0  ...                      0.0   \n",
      "1                     0.0  ...                      0.0   \n",
      "2                     0.0  ...                      0.0   \n",
      "3                     0.0  ...                      0.0   \n",
      "4                     0.0  ...                      0.0   \n",
      "\n",
      "   onehotencoder__x32_b'3'  onehotencoder__x32_b'5'  onehotencoder__x32_b'U'  \\\n",
      "0                      1.0                      0.0                      0.0   \n",
      "1                      1.0                      0.0                      0.0   \n",
      "2                      1.0                      0.0                      0.0   \n",
      "3                      1.0                      0.0                      0.0   \n",
      "4                      1.0                      0.0                      0.0   \n",
      "\n",
      "   carbon  hardness  strength  thick   width    len  \n",
      "0     8.0       0.0       0.0  0.700   610.0    0.0  \n",
      "1     0.0       0.0       0.0  3.200   610.0    0.0  \n",
      "2     0.0       0.0       0.0  0.700  1300.0  762.0  \n",
      "3     0.0      60.0       0.0  2.801   385.1    0.0  \n",
      "4     0.0      60.0       0.0  0.801   255.0  269.0  \n",
      "\n",
      "[5 rows x 89 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduard/anaconda3/envs/academic_experiments_conda_venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transformer = make_column_transformer(\n",
    "    (OneHotEncoder(), non_numeric_columns),\n",
    "    remainder='passthrough')\n",
    "\n",
    "transformed = transformer.fit_transform(data_example_df)\n",
    "transformed_df = pd.DataFrame(transformed, columns=transformer.get_feature_names())\n",
    "print(transformed_df.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['onehotencoder__x0_b'?'', 'onehotencoder__x0_b'TN'',\n       'onehotencoder__x0_b'ZS'', 'onehotencoder__x1_b'C'',\n       'onehotencoder__x2_b'?'', 'onehotencoder__x2_b'A'',\n       'onehotencoder__x2_b'K'', 'onehotencoder__x2_b'M'',\n       'onehotencoder__x2_b'R'', 'onehotencoder__x2_b'S'',\n       'onehotencoder__x2_b'V'', 'onehotencoder__x2_b'W'',\n       'onehotencoder__x3_b'?'', 'onehotencoder__x3_b'T'',\n       'onehotencoder__x4_b'?'', 'onehotencoder__x4_b'A'',\n       'onehotencoder__x4_b'S'', 'onehotencoder__x5_b'1'',\n       'onehotencoder__x5_b'2'', 'onehotencoder__x5_b'3'',\n       'onehotencoder__x5_b'5'', 'onehotencoder__x5_b'?'',\n       'onehotencoder__x6_b'?'', 'onehotencoder__x6_b'N'',\n       'onehotencoder__x7_b'?'', 'onehotencoder__x7_b'P'',\n       'onehotencoder__x8_b'?'', 'onehotencoder__x8_b'D'',\n       'onehotencoder__x8_b'E'', 'onehotencoder__x8_b'F'',\n       'onehotencoder__x8_b'G'', 'onehotencoder__x9_b'1'',\n       'onehotencoder__x9_b'2'', 'onehotencoder__x9_b'?'',\n       'onehotencoder__x10_b'?'', 'onehotencoder__x10_b'Y'',\n       'onehotencoder__x11_b'?'', 'onehotencoder__x11_b'Y'',\n       'onehotencoder__x12_b'?'', 'onehotencoder__x12_b'Y'',\n       'onehotencoder__x13_b'?'', 'onehotencoder__x13_b'B'',\n       'onehotencoder__x13_b'M'', 'onehotencoder__x14_b'?'',\n       'onehotencoder__x14_b'Y'', 'onehotencoder__x15_b'?'',\n       'onehotencoder__x16_b'?'', 'onehotencoder__x16_b'C'',\n       'onehotencoder__x17_b'?'', 'onehotencoder__x17_b'P'',\n       'onehotencoder__x18_b'?'', 'onehotencoder__x18_b'Y'',\n       'onehotencoder__x19_b'?'', 'onehotencoder__x20_b'?'',\n       'onehotencoder__x20_b'Y'', 'onehotencoder__x21_b'?'',\n       'onehotencoder__x21_b'Y'', 'onehotencoder__x22_b'?'',\n       'onehotencoder__x23_b'?'', 'onehotencoder__x23_b'B'',\n       'onehotencoder__x23_b'C'', 'onehotencoder__x23_b'V'',\n       'onehotencoder__x24_b'?'', 'onehotencoder__x24_b'Y'',\n       'onehotencoder__x25_b'?'', 'onehotencoder__x26_b'?'',\n       'onehotencoder__x27_b'?'', 'onehotencoder__x28_b'COIL'',\n       'onehotencoder__x28_b'SHEET'', 'onehotencoder__x29_b'?'',\n       'onehotencoder__x29_b'N'', 'onehotencoder__x29_b'Y'',\n       'onehotencoder__x30_b'0'', 'onehotencoder__x30_b'500'',\n       'onehotencoder__x30_b'600'', 'onehotencoder__x31_b'2'',\n       'onehotencoder__x31_b'3'', 'onehotencoder__x31_b'?'',\n       'onehotencoder__x32_b'1'', 'onehotencoder__x32_b'2'',\n       'onehotencoder__x32_b'3'', 'onehotencoder__x32_b'5'',\n       'onehotencoder__x32_b'U'', 'carbon', 'hardness', 'strength', 'thick',\n       'width', 'len'],\n      dtype='object')"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduard/anaconda3/envs/academic_experiments_conda_venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['onehotencoder__x0_Adelie',\n 'onehotencoder__x0_Chinstrap',\n 'onehotencoder__x0_Gentoo',\n 'onehotencoder__x1_Biscoe',\n 'onehotencoder__x1_Dream',\n 'onehotencoder__x1_Torgersen',\n 'onehotencoder__x2_32.1',\n 'onehotencoder__x2_33.1',\n 'onehotencoder__x2_33.5',\n 'onehotencoder__x2_34.0',\n 'onehotencoder__x2_34.4',\n 'onehotencoder__x2_34.5',\n 'onehotencoder__x2_34.6',\n 'onehotencoder__x2_35.0',\n 'onehotencoder__x2_35.1',\n 'onehotencoder__x2_35.2',\n 'onehotencoder__x2_35.3',\n 'onehotencoder__x2_35.5',\n 'onehotencoder__x2_35.6',\n 'onehotencoder__x2_35.7',\n 'onehotencoder__x2_35.9',\n 'onehotencoder__x2_36.0',\n 'onehotencoder__x2_36.2',\n 'onehotencoder__x2_36.3',\n 'onehotencoder__x2_36.4',\n 'onehotencoder__x2_36.5',\n 'onehotencoder__x2_36.6',\n 'onehotencoder__x2_36.7',\n 'onehotencoder__x2_36.8',\n 'onehotencoder__x2_36.9',\n 'onehotencoder__x2_37.0',\n 'onehotencoder__x2_37.2',\n 'onehotencoder__x2_37.3',\n 'onehotencoder__x2_37.5',\n 'onehotencoder__x2_37.6',\n 'onehotencoder__x2_37.7',\n 'onehotencoder__x2_37.8',\n 'onehotencoder__x2_37.9',\n 'onehotencoder__x2_38.1',\n 'onehotencoder__x2_38.2',\n 'onehotencoder__x2_38.3',\n 'onehotencoder__x2_38.5',\n 'onehotencoder__x2_38.6',\n 'onehotencoder__x2_38.7',\n 'onehotencoder__x2_38.8',\n 'onehotencoder__x2_38.9',\n 'onehotencoder__x2_39.0',\n 'onehotencoder__x2_39.1',\n 'onehotencoder__x2_39.2',\n 'onehotencoder__x2_39.3',\n 'onehotencoder__x2_39.5',\n 'onehotencoder__x2_39.6',\n 'onehotencoder__x2_39.7',\n 'onehotencoder__x2_39.8',\n 'onehotencoder__x2_40.1',\n 'onehotencoder__x2_40.2',\n 'onehotencoder__x2_40.3',\n 'onehotencoder__x2_40.5',\n 'onehotencoder__x2_40.6',\n 'onehotencoder__x2_40.7',\n 'onehotencoder__x2_40.8',\n 'onehotencoder__x2_40.9',\n 'onehotencoder__x2_41.0',\n 'onehotencoder__x2_41.1',\n 'onehotencoder__x2_41.3',\n 'onehotencoder__x2_41.4',\n 'onehotencoder__x2_41.5',\n 'onehotencoder__x2_41.6',\n 'onehotencoder__x2_41.7',\n 'onehotencoder__x2_41.8',\n 'onehotencoder__x2_42.0',\n 'onehotencoder__x2_42.1',\n 'onehotencoder__x2_42.2',\n 'onehotencoder__x2_42.3',\n 'onehotencoder__x2_42.4',\n 'onehotencoder__x2_42.5',\n 'onehotencoder__x2_42.6',\n 'onehotencoder__x2_42.7',\n 'onehotencoder__x2_42.8',\n 'onehotencoder__x2_42.9',\n 'onehotencoder__x2_43.1',\n 'onehotencoder__x2_43.2',\n 'onehotencoder__x2_43.3',\n 'onehotencoder__x2_43.4',\n 'onehotencoder__x2_43.5',\n 'onehotencoder__x2_43.6',\n 'onehotencoder__x2_43.8',\n 'onehotencoder__x2_44.0',\n 'onehotencoder__x2_44.1',\n 'onehotencoder__x2_44.4',\n 'onehotencoder__x2_44.5',\n 'onehotencoder__x2_44.9',\n 'onehotencoder__x2_45.0',\n 'onehotencoder__x2_45.1',\n 'onehotencoder__x2_45.2',\n 'onehotencoder__x2_45.3',\n 'onehotencoder__x2_45.4',\n 'onehotencoder__x2_45.5',\n 'onehotencoder__x2_45.6',\n 'onehotencoder__x2_45.7',\n 'onehotencoder__x2_45.8',\n 'onehotencoder__x2_45.9',\n 'onehotencoder__x2_46.0',\n 'onehotencoder__x2_46.1',\n 'onehotencoder__x2_46.2',\n 'onehotencoder__x2_46.3',\n 'onehotencoder__x2_46.4',\n 'onehotencoder__x2_46.5',\n 'onehotencoder__x2_46.6',\n 'onehotencoder__x2_46.7',\n 'onehotencoder__x2_46.8',\n 'onehotencoder__x2_46.9',\n 'onehotencoder__x2_47.0',\n 'onehotencoder__x2_47.2',\n 'onehotencoder__x2_47.3',\n 'onehotencoder__x2_47.4',\n 'onehotencoder__x2_47.5',\n 'onehotencoder__x2_47.6',\n 'onehotencoder__x2_47.7',\n 'onehotencoder__x2_47.8',\n 'onehotencoder__x2_48.1',\n 'onehotencoder__x2_48.2',\n 'onehotencoder__x2_48.4',\n 'onehotencoder__x2_48.5',\n 'onehotencoder__x2_48.6',\n 'onehotencoder__x2_48.7',\n 'onehotencoder__x2_48.8',\n 'onehotencoder__x2_49.0',\n 'onehotencoder__x2_49.1',\n 'onehotencoder__x2_49.2',\n 'onehotencoder__x2_49.3',\n 'onehotencoder__x2_49.4',\n 'onehotencoder__x2_49.5',\n 'onehotencoder__x2_49.6',\n 'onehotencoder__x2_49.7',\n 'onehotencoder__x2_49.8',\n 'onehotencoder__x2_49.9',\n 'onehotencoder__x2_50.0',\n 'onehotencoder__x2_50.1',\n 'onehotencoder__x2_50.2',\n 'onehotencoder__x2_50.3',\n 'onehotencoder__x2_50.4',\n 'onehotencoder__x2_50.5',\n 'onehotencoder__x2_50.6',\n 'onehotencoder__x2_50.7',\n 'onehotencoder__x2_50.8',\n 'onehotencoder__x2_50.9',\n 'onehotencoder__x2_51.0',\n 'onehotencoder__x2_51.1',\n 'onehotencoder__x2_51.3',\n 'onehotencoder__x2_51.4',\n 'onehotencoder__x2_51.5',\n 'onehotencoder__x2_51.7',\n 'onehotencoder__x2_51.9',\n 'onehotencoder__x2_52.0',\n 'onehotencoder__x2_52.1',\n 'onehotencoder__x2_52.2',\n 'onehotencoder__x2_52.5',\n 'onehotencoder__x2_52.7',\n 'onehotencoder__x2_52.8',\n 'onehotencoder__x2_53.4',\n 'onehotencoder__x2_53.5',\n 'onehotencoder__x2_54.2',\n 'onehotencoder__x2_54.3',\n 'onehotencoder__x2_55.1',\n 'onehotencoder__x2_55.8',\n 'onehotencoder__x2_55.9',\n 'onehotencoder__x2_58.0',\n 'onehotencoder__x2_59.6',\n 'onehotencoder__x3_13.1',\n 'onehotencoder__x3_13.2',\n 'onehotencoder__x3_13.3',\n 'onehotencoder__x3_13.4',\n 'onehotencoder__x3_13.5',\n 'onehotencoder__x3_13.6',\n 'onehotencoder__x3_13.7',\n 'onehotencoder__x3_13.8',\n 'onehotencoder__x3_13.9',\n 'onehotencoder__x3_14.0',\n 'onehotencoder__x3_14.1',\n 'onehotencoder__x3_14.2',\n 'onehotencoder__x3_14.3',\n 'onehotencoder__x3_14.4',\n 'onehotencoder__x3_14.5',\n 'onehotencoder__x3_14.6',\n 'onehotencoder__x3_14.7',\n 'onehotencoder__x3_14.8',\n 'onehotencoder__x3_14.9',\n 'onehotencoder__x3_15.0',\n 'onehotencoder__x3_15.1',\n 'onehotencoder__x3_15.2',\n 'onehotencoder__x3_15.3',\n 'onehotencoder__x3_15.4',\n 'onehotencoder__x3_15.5',\n 'onehotencoder__x3_15.6',\n 'onehotencoder__x3_15.7',\n 'onehotencoder__x3_15.8',\n 'onehotencoder__x3_15.9',\n 'onehotencoder__x3_16.0',\n 'onehotencoder__x3_16.1',\n 'onehotencoder__x3_16.2',\n 'onehotencoder__x3_16.3',\n 'onehotencoder__x3_16.4',\n 'onehotencoder__x3_16.5',\n 'onehotencoder__x3_16.6',\n 'onehotencoder__x3_16.7',\n 'onehotencoder__x3_16.8',\n 'onehotencoder__x3_16.9',\n 'onehotencoder__x3_17.0',\n 'onehotencoder__x3_17.1',\n 'onehotencoder__x3_17.2',\n 'onehotencoder__x3_17.3',\n 'onehotencoder__x3_17.4',\n 'onehotencoder__x3_17.5',\n 'onehotencoder__x3_17.6',\n 'onehotencoder__x3_17.7',\n 'onehotencoder__x3_17.8',\n 'onehotencoder__x3_17.9',\n 'onehotencoder__x3_18.0',\n 'onehotencoder__x3_18.1',\n 'onehotencoder__x3_18.2',\n 'onehotencoder__x3_18.3',\n 'onehotencoder__x3_18.4',\n 'onehotencoder__x3_18.5',\n 'onehotencoder__x3_18.6',\n 'onehotencoder__x3_18.7',\n 'onehotencoder__x3_18.8',\n 'onehotencoder__x3_18.9',\n 'onehotencoder__x3_19.0',\n 'onehotencoder__x3_19.1',\n 'onehotencoder__x3_19.2',\n 'onehotencoder__x3_19.3',\n 'onehotencoder__x3_19.4',\n 'onehotencoder__x3_19.5',\n 'onehotencoder__x3_19.6',\n 'onehotencoder__x3_19.7',\n 'onehotencoder__x3_19.8',\n 'onehotencoder__x3_19.9',\n 'onehotencoder__x3_20.0',\n 'onehotencoder__x3_20.1',\n 'onehotencoder__x3_20.3',\n 'onehotencoder__x3_20.5',\n 'onehotencoder__x3_20.6',\n 'onehotencoder__x3_20.7',\n 'onehotencoder__x3_20.8',\n 'onehotencoder__x3_21.1',\n 'onehotencoder__x3_21.2',\n 'onehotencoder__x3_21.5',\n 'onehotencoder__x4_172.0',\n 'onehotencoder__x4_174.0',\n 'onehotencoder__x4_176.0',\n 'onehotencoder__x4_178.0',\n 'onehotencoder__x4_180.0',\n 'onehotencoder__x4_181.0',\n 'onehotencoder__x4_182.0',\n 'onehotencoder__x4_183.0',\n 'onehotencoder__x4_184.0',\n 'onehotencoder__x4_185.0',\n 'onehotencoder__x4_186.0',\n 'onehotencoder__x4_187.0',\n 'onehotencoder__x4_188.0',\n 'onehotencoder__x4_189.0',\n 'onehotencoder__x4_190.0',\n 'onehotencoder__x4_191.0',\n 'onehotencoder__x4_192.0',\n 'onehotencoder__x4_193.0',\n 'onehotencoder__x4_194.0',\n 'onehotencoder__x4_195.0',\n 'onehotencoder__x4_196.0',\n 'onehotencoder__x4_197.0',\n 'onehotencoder__x4_198.0',\n 'onehotencoder__x4_199.0',\n 'onehotencoder__x4_200.0',\n 'onehotencoder__x4_201.0',\n 'onehotencoder__x4_202.0',\n 'onehotencoder__x4_203.0',\n 'onehotencoder__x4_205.0',\n 'onehotencoder__x4_206.0',\n 'onehotencoder__x4_207.0',\n 'onehotencoder__x4_208.0',\n 'onehotencoder__x4_209.0',\n 'onehotencoder__x4_210.0',\n 'onehotencoder__x4_211.0',\n 'onehotencoder__x4_212.0',\n 'onehotencoder__x4_213.0',\n 'onehotencoder__x4_214.0',\n 'onehotencoder__x4_215.0',\n 'onehotencoder__x4_216.0',\n 'onehotencoder__x4_217.0',\n 'onehotencoder__x4_218.0',\n 'onehotencoder__x4_219.0',\n 'onehotencoder__x4_220.0',\n 'onehotencoder__x4_221.0',\n 'onehotencoder__x4_222.0',\n 'onehotencoder__x4_223.0',\n 'onehotencoder__x4_224.0',\n 'onehotencoder__x4_225.0',\n 'onehotencoder__x4_226.0',\n 'onehotencoder__x4_228.0',\n 'onehotencoder__x4_229.0',\n 'onehotencoder__x4_230.0',\n 'onehotencoder__x4_231.0',\n 'onehotencoder__x5_2700.0',\n 'onehotencoder__x5_2850.0',\n 'onehotencoder__x5_2900.0',\n 'onehotencoder__x5_2925.0',\n 'onehotencoder__x5_3000.0',\n 'onehotencoder__x5_3050.0',\n 'onehotencoder__x5_3075.0',\n 'onehotencoder__x5_3100.0',\n 'onehotencoder__x5_3150.0',\n 'onehotencoder__x5_3175.0',\n 'onehotencoder__x5_3200.0',\n 'onehotencoder__x5_3250.0',\n 'onehotencoder__x5_3275.0',\n 'onehotencoder__x5_3300.0',\n 'onehotencoder__x5_3325.0',\n 'onehotencoder__x5_3350.0',\n 'onehotencoder__x5_3400.0',\n 'onehotencoder__x5_3425.0',\n 'onehotencoder__x5_3450.0',\n 'onehotencoder__x5_3475.0',\n 'onehotencoder__x5_3500.0',\n 'onehotencoder__x5_3525.0',\n 'onehotencoder__x5_3550.0',\n 'onehotencoder__x5_3575.0',\n 'onehotencoder__x5_3600.0',\n 'onehotencoder__x5_3625.0',\n 'onehotencoder__x5_3650.0',\n 'onehotencoder__x5_3675.0',\n 'onehotencoder__x5_3700.0',\n 'onehotencoder__x5_3725.0',\n 'onehotencoder__x5_3750.0',\n 'onehotencoder__x5_3775.0',\n 'onehotencoder__x5_3800.0',\n 'onehotencoder__x5_3825.0',\n 'onehotencoder__x5_3850.0',\n 'onehotencoder__x5_3875.0',\n 'onehotencoder__x5_3900.0',\n 'onehotencoder__x5_3950.0',\n 'onehotencoder__x5_3975.0',\n 'onehotencoder__x5_4000.0',\n 'onehotencoder__x5_4050.0',\n 'onehotencoder__x5_4075.0',\n 'onehotencoder__x5_4100.0',\n 'onehotencoder__x5_4150.0',\n 'onehotencoder__x5_4200.0',\n 'onehotencoder__x5_4250.0',\n 'onehotencoder__x5_4275.0',\n 'onehotencoder__x5_4300.0',\n 'onehotencoder__x5_4350.0',\n 'onehotencoder__x5_4375.0',\n 'onehotencoder__x5_4400.0',\n 'onehotencoder__x5_4450.0',\n 'onehotencoder__x5_4475.0',\n 'onehotencoder__x5_4500.0',\n 'onehotencoder__x5_4550.0',\n 'onehotencoder__x5_4575.0',\n 'onehotencoder__x5_4600.0',\n 'onehotencoder__x5_4625.0',\n 'onehotencoder__x5_4650.0',\n 'onehotencoder__x5_4675.0',\n 'onehotencoder__x5_4700.0',\n 'onehotencoder__x5_4725.0',\n 'onehotencoder__x5_4750.0',\n 'onehotencoder__x5_4775.0',\n 'onehotencoder__x5_4800.0',\n 'onehotencoder__x5_4850.0',\n 'onehotencoder__x5_4875.0',\n 'onehotencoder__x5_4900.0',\n 'onehotencoder__x5_4925.0',\n 'onehotencoder__x5_4950.0',\n 'onehotencoder__x5_4975.0',\n 'onehotencoder__x5_5000.0',\n 'onehotencoder__x5_5050.0',\n 'onehotencoder__x5_5100.0',\n 'onehotencoder__x5_5150.0',\n 'onehotencoder__x5_5200.0',\n 'onehotencoder__x5_5250.0',\n 'onehotencoder__x5_5300.0',\n 'onehotencoder__x5_5350.0',\n 'onehotencoder__x5_5400.0',\n 'onehotencoder__x5_5450.0',\n 'onehotencoder__x5_5500.0',\n 'onehotencoder__x5_5550.0',\n 'onehotencoder__x5_5600.0',\n 'onehotencoder__x5_5650.0',\n 'onehotencoder__x5_5700.0',\n 'onehotencoder__x5_5750.0',\n 'onehotencoder__x5_5800.0',\n 'onehotencoder__x5_5850.0',\n 'onehotencoder__x5_5950.0',\n 'onehotencoder__x5_6000.0',\n 'onehotencoder__x5_6050.0',\n 'onehotencoder__x5_6300.0',\n 'onehotencoder__x6_Female',\n 'onehotencoder__x6_Male']"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.get_feature_names()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: b'?'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DecisionTreeClassifier\n\u001B[1;32m      3\u001B[0m reg_tree \u001B[38;5;241m=\u001B[39m DecisionTreeClassifier(max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m17\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mreg_tree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m reg_tree_pred \u001B[38;5;241m=\u001B[39m reg_tree\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[0;32m~/anaconda3/envs/academic_experiments_conda_venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:969\u001B[0m, in \u001B[0;36mDecisionTreeClassifier.fit\u001B[0;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[1;32m    939\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    940\u001B[0m     \u001B[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001B[39;00m\n\u001B[1;32m    941\u001B[0m \n\u001B[1;32m    942\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    966\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[1;32m    967\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 969\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    970\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    971\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    974\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    975\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/academic_experiments_conda_venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:172\u001B[0m, in \u001B[0;36mBaseDecisionTree.fit\u001B[0;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[1;32m    170\u001B[0m check_X_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(dtype\u001B[38;5;241m=\u001B[39mDTYPE, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    171\u001B[0m check_y_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m--> 172\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate_separately\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcheck_X_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_y_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(X):\n\u001B[1;32m    176\u001B[0m     X\u001B[38;5;241m.\u001B[39msort_indices()\n",
      "File \u001B[0;32m~/anaconda3/envs/academic_experiments_conda_venv/lib/python3.10/site-packages/sklearn/base.py:591\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m check_X_params:\n\u001B[1;32m    590\u001B[0m     check_X_params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdefault_check_params, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_X_params}\n\u001B[0;32m--> 591\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_X_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    592\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m check_y_params:\n\u001B[1;32m    593\u001B[0m     check_y_params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdefault_check_params, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params}\n",
      "File \u001B[0;32m~/anaconda3/envs/academic_experiments_conda_venv/lib/python3.10/site-packages/sklearn/utils/validation.py:856\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    854\u001B[0m         array \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mastype(dtype, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m\"\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 856\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[1;32m    858\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    859\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[1;32m    860\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: b'?'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "reg_tree = DecisionTreeClassifier(max_depth=5, random_state=17)\n",
    "\n",
    "reg_tree.fit(X_train, Y_train)\n",
    "reg_tree_pred = reg_tree.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_example_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdata_example_df\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_example_df' is not defined"
     ]
    }
   ],
   "source": [
    "data_example_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
